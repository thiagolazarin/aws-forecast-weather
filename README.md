# ğŸŒ¤ï¸ PrevisÃ£o de Temperatura com Machine Learning e AWS

Este projeto automatiza a previsÃ£o de temperatura para diferentes cidades, utilizando dados da API Open-Meteo, machine learning com Python e infraestrutura em nuvem da AWS. O resultado Ã© visualizado em tempo real no Power BI atravÃ©s do Amazon Athena.

---

## ğŸš€ Tecnologias Utilizadas
O projeto foi desenvolvido atravÃ©s do AWS SAM CLI localmente.
- **Python + Jupyter Notebook** (prÃ©-processamento e modelagem)
- **Docker** (Executar localmente funÃ§Ãµes lambda)
- **AWS S3** (armazenamento de dados e modelos)
- **AWS Lambda** (execuÃ§Ã£o automatizada de previsÃµes e gatilhos)
- **AWS Glue Crawler** (catÃ¡logo automÃ¡tico de dados)
- **Amazon Athena** (consulta SQL sobre dados particionados)
- **Power BI** (visualizaÃ§Ã£o dos resultados)
- **Open-Meteo API** (dados de clima abertos)

---

## ğŸ§  Funcionalidade do Projeto

1. **ExtraÃ§Ã£o de Dados**
   - Usa Jupyter para coletar dados histÃ³ricos da Open-Meteo

2. **Modelagem**
   - Treina um modelo de machine learning (SVR) com features temporais
   - Salva o modelo e o scaler em um bucket S3

3. **Agendamento**
   - Um agendador do Windows executa a previsÃ£o semanalmente via script Python a cada 7 dias

4. **ExecuÃ§Ã£o da PrevisÃ£o**
   - Um Lambda executa o modelo, gera previsÃµes para 7 dias e salva no S3 em formato particionado (`data=` e `cidade=`)

5. **AtualizaÃ§Ã£o automÃ¡tica**
   - Outro Lambda escuta o S3 e dispara o Glue Crawler para atualizar o catÃ¡logo

6. **Consulta e VisualizaÃ§Ã£o**
   - Dados sÃ£o consultados via Athena e visualizados no Power BI via ODBC

---

## InformaÃ§Ãµes sobre a criaÃ§Ã£o do modelo de machine learning:
1. AnÃ¡lise e coleta dos dados do open meteo salvo no bucket S3
2. Os dados utilizados no treinamento sÃ£o do ano de 2024, totalizando 8784 registros.
3. A terceira etapa foi de treinamento e avaliaÃ§Ã£o do modelo:

O modelo de previsÃ£o de temperatura foi treinado com as seguintes variÃ¡veis climÃ¡ticas e temporais:

ğŸŒ¦ï¸ VariÃ¡veis ClimÃ¡ticas:

relative_humidity_2m: Umidade relativa do ar a 2 metros de altura

apparent_temperature: Temperatura aparente considerando vento e umidade

precipitation: Volume de precipitaÃ§Ã£o acumulado em um perÃ­odo

rain: Indicador binÃ¡rio de ocorrÃªncia de chuva

weather_code: CÃ³digo que representa a condiÃ§Ã£o climÃ¡tica

cloud_cover: Percentual de cobertura de nuvens

wind_direction_10m: DireÃ§Ã£o do vento a 10 metros de altura

wind_speed_10m: Velocidade do vento a 10 metros de altura

is_day: Indicador binÃ¡rio para diferenciar dia e noite

ğŸ•’ VariÃ¡veis Temporais Derivadas (Engenharia de Features):

hour_sin e hour_cos: Representam a hora do dia de forma cÃ­clica, preservando periodicidade horÃ¡ria

month_sin e month_cos: Representam o mÃªs do ano com sazonalidade cÃ­clica

Essas variÃ¡veis derivadas ajudam o modelo a compreender padrÃµes temporais sem introduzir ordinalidade indevida.

# AvaliaÃ§Ã£o do modelo:
MAE (Erro MÃ©dio Absoluto): Mede o erro mÃ©dio absoluto entre os valores reais e previstos. Quanto menor, melhor. Indica que o modelo, em mÃ©dia, erra 0.0950 unidades.

RMSE (Raiz do Erro QuadrÃ¡tico MÃ©dio): Mede o erro mÃ©dio, penalizando mais fortemente erros maiores. Um RMSE de 0.1589 indica que os erros do modelo tÃªm baixa magnitude.

RÂ² (Coeficiente de DeterminaÃ§Ã£o): Mede o quanto da variabilidade dos dados o modelo consegue explicar. Um RÂ² de 0.9990 mostra que o modelo explica 99,90% da variÃ¢ncia dos dados â€” excelente desempenho.

MAPE (Percentual do Erro MÃ©dio Absoluto): Expressa o erro mÃ©dio absoluto em termos percentuais. Um MAPE de 0.0042 (ou 0,42%) indica altÃ­ssima precisÃ£o nas previsÃµes.

## ğŸ—‚ï¸ Estrutura de Pastas
```
EXTRACT-DATA-FORECAST/
â”œâ”€â”€ aws_lambda/              # CÃ³digo da Lambda que gera previsÃµes
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ predict_lambda.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ events/
â”‚   â””â”€â”€ event.json           # Exemplo de evento de teste para a Lambda
â”œâ”€â”€ load-data/
â”‚   â””â”€â”€ data-extract.ipynb   # Notebook para extrair dados histÃ³ricos do Open-Meteo
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ forecast_weather.ipynb
â”‚   â”œâ”€â”€ scaler.pkl           # Scaler do modelo
â”‚   â””â”€â”€ svr_model.pkl        # Modelo treinado (SVR)
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ .gitignore
â”œâ”€â”€ samconfig.toml           # ConfiguraÃ§Ã£o SAM CLI
â”œâ”€â”€ README.md                # Este arquivo
â””â”€â”€ .aws-sam/                # Ignorado (build temporÃ¡rio do SAM)
```

## âš™ï¸ Fluxo de ExecuÃ§Ã£o

1. **load-data**: coleta dados histÃ³ricos com Jupyter + Open-Meteo
2. **ml**: treina modelo SVR com features de hora e mÃªs (seno/cosseno)
3. **agendador windows**: O agendador do windows roda a cada 7 dias e coloca todo o processo em produÃ§Ã£o.
3. **aws_lambda**: Lambda gera previsÃ£o dos prÃ³ximos 7 dias e salva JSON particionado no S3
4. **Crawler**: Ã© acionado automaticamente por outra Lambda quando um novo arquivo Ã© salvo no bucket
5. **Athena**: consulta os dados no formato `data=YYYY-MM-DD`, `cidade=sao_paulo`, etc.
6. **Power BI**: conexÃ£o via ODBC com Athena para visualizaÃ§Ã£o

### Print de temperatura prevista x real em janeiro e fevereiro:
![alt text](image-1.png)

![alt text](image-2.png)


### ğŸ“Š Exemplo de Dashboard
![Dashboard no Power BI](img/img-dash.png)